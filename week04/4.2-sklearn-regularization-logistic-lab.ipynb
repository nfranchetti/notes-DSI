{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Greenness\" Of Content\n",
    "\n",
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender and was made available [here](https://www.kaggle.com/c/stumbleupon/download/train.tsv)\n",
    "\n",
    "A description of the columns is below\n",
    "\n",
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonLinkRatio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonLinkRatio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonLinkRatio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonLinkRatio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are 'evergreen' sites?\n",
    "- These are websites that always relevant like recipies or reviews (as opposed to current events)\n",
    "- Look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../assets/datasets/train.tsv', sep='\\t', na_values='?')\n",
    "\n",
    "# Extract the title and body from the boilerplate JSON text\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', '')).fillna('')\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', '')).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[['title', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In previous lessons, we added text features manually as below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['recipe'] = data['title'].str.lower().str.contains('recipe')\n",
    "data['electronic'] = data['title'].str.lower().str.contains('electronic')\n",
    "data['tips'] = data['title'].str.lower().str.contains('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can build a Logistic Regression model using scikit-learn and examine the coefficients\n",
    "- Examine the coefficients using the `examine_coefficients` function provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def examine_coefficients(model, df):\n",
    "    df = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df[df.Coefficient !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = data[[\n",
    "        'recipe',\n",
    "        'electronic',\n",
    "        'tips'\n",
    "    ]]\n",
    "y = data.label\n",
    "\n",
    "\n",
    "model = LogisticRegression() \n",
    "\n",
    "model.fit(X, y) # This fits the model to learn the coefficients\n",
    "examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can build text features in bulk as well using built-in preprocessing tools\n",
    "- `CountVectorizer` builds a feature per word automatically as we did manually for `recipe`, `electronic` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(\n",
    "    binary=True,  # Create binary features\n",
    "    stop_words='english', # Ignore common words such as 'the', 'and'\n",
    "    max_features=50, # Only use the top 50 most common words\n",
    ")\n",
    "\n",
    "\n",
    "# This builds a matrix with a row per website (or data point) and column per word (using all words in the dataset)\n",
    "X = v.fit_transform(data.title).todense()\n",
    "X = pd.DataFrame(X, columns=v.get_feature_names())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the input matrix above, fit a logistic regression model using L1 regularization\n",
    "- Change the `C` parameter\n",
    "    - how do the coefficients change? (use `examine_coeffcients`)\n",
    "    - how does the model perfomance change (using AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the input matrix above, fit a logistic regression model using L2 regularization\n",
    "- Change the `C` parameter - how do the coefficients change? (use `examine_coeffcients`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
