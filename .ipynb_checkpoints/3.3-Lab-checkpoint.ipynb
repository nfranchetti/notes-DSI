{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Boston Housing dataset\n",
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling our data\n",
    "\n",
    "Let's see what effect scaling our data has on some of the features by picking two features\n",
    "that have a large difference in scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "\n",
    "Let's apply standardization, transforming our data to have mean zero $(\\mu = 0)$ and variance 1 $(\\sigma^2 = 1)$ by the formula:\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "mean = np.mean(xs)\n",
    "std = np.std(xs)\n",
    "xs = [(x - mean) / std for x in xs]\n",
    "\n",
    "ys = df[\"TAX\"]\n",
    "mean = np.mean(ys)\n",
    "std = np.std(ys)\n",
    "ys = [(y - mean) / std for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we did not change the shape of the data, just its scale. You can also use scikit-learn to standardize your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "xs = preprocessing.scale(df[\"NOX\"])\n",
    "ys = preprocessing.scale(df[\"TAX\"])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling\n",
    "\n",
    "To Min-Max scale our data, we use the formula:\n",
    "\n",
    "$$x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "xmin = np.min(xs)\n",
    "xmax = np.max(xs)\n",
    "xs = [(x - xmin) / (xmax - xmin) for x in xs]\n",
    "\n",
    "ys = df[\"TAX\"]\n",
    "ymin = np.min(ys)\n",
    "ymax = np.max(ys)\n",
    "ys = [(y - ymin) / (ymax - ymin) for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can use scikit-learn to Min-Max Scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "xs = scaler.fit_transform(df[[\"NOX\"]])\n",
    "ys = scaler.fit_transform(df[[\"TAX\"]])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "We normalize the data by dividing through by some kind of sum or total. For example, it's common to normalize simply by the (*L1*) sum $|X| = \\sum_{x \\in X}{x}$ or by the (*L2*) euclidean sum of squares distance  $||X|| = \\sqrt{\\sum_{x \\in X}{x^2}}$:\n",
    "\n",
    "$$x' = \\frac{x}{|X|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Practice\n",
    "\n",
    "Perform normalization by both the L1 and L2 sums and plot as we did for the other scaling methods.\n",
    "\n",
    "If you finish early, repeat the exercise [using scikit-learn](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "# Normalize xs and ys with L1 sum\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX L1 Normalized\")\n",
    "plt.ylabel(\"TAX L1 Normalized\")\n",
    "plt.show()\n",
    "\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "# Normalize xs and ys with L2 sum\n",
    "\n",
    "plt.scatter(xs, ys, color='g')\n",
    "plt.xlabel(\"NOX L2 Normalized\")\n",
    "plt.ylabel(\"TAX L2 Normalized\")\n",
    "plt.show()\n",
    "\n",
    "# Sklearn\n",
    "# Use preprocessing.normalize on xs and ys\n",
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX L1 Normalized\")\n",
    "plt.ylabel(\"TAX L1 Normalized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Practice\n",
    "\n",
    "Let's practice linear fits using feature scaling. For each of the three scaling methods we've discussed:\n",
    "* Practice scaling and linear fits on the boston housing data using all the data (scaled) versus the target data `boston.target`. Does scaling or normalization affect any of your models? Determine if the model fit score changed. Explain why or why not. (10-20 mins).\n",
    "\n",
    "Next:\n",
    "* Try some regularized models. Does scaling have a significant effect on the fit? (10 mins)\n",
    "* Try some other models from scikit-learn, such as a [SGDRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html).\n",
    "It's ok if you are unfamiliar with the model, just follow the example code\n",
    "and explore the fit and the effect of scaling. (10 mins)\n",
    "* Bonus: try a few extra models like a [support vector machine](http://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html). What do you think\n",
    "about the goodness of fit? Scaling is _required_ for this model.\n",
    "\n",
    "### Bonus Exercises\n",
    "\n",
    "Using Scikit-learn, fit some other model to the data, for example a regularization model like a Ridge or Lasso, a [SGDRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html), or a [support vector machine](http://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html). Do any of the scaling methods affect the goodness of fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all basically the same, here's one example.\n",
    "# The linear regression fit score is not affected by scaling since the coefficients adapt.\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "\n",
    "X = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stochastic Regressor -- scaling makes a huge difference\n",
    "# linear_model.SGDRegressor()\n",
    "\n",
    "# Unscaled\n",
    "\n",
    "\n",
    "\n",
    "# Scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
