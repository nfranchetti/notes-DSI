{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Lab\n",
    "\n",
    "In this lab we will further explore Scikit's and NLTK's capabilities to process text. We will use the 20 Newsgroup dataset, which is provided by Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sklearn.datasets.twenty_newsgroups\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1. What data taype is `data_train`\n",
    "- Is it like a list? Or like a Dictionary? or what?\n",
    "- How many data points does it contain?\n",
    "- Inspect the first data point, what does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi,\\n\\nI've noticed that if you only save a mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nSeems to be, barring evidence to the contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n &gt;In article &lt;1993Apr19.020359.26996@sq.sq.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have a request for those who would like to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AW&amp;ST  had a brief blurb on a Manned Lunar Exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nThere are definitely quite a few horrible de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mark Prado\\n  \\n  \\nOld pioneer song from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nAcorn Replay running on a 25MHz ARM 3 proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nTheir Hiten engineering-test mission spent a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm interested in find out what is involved in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a\\n\\nWhat about positional uncertainties in S-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I would like to program Tseng ET4000 to nonsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In-Reply-To: &lt;20APR199312262902@rigel.tamu.edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n\\n\\n\\nI'm not sure, but it almost sounds lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hello,\\n     I am looking to add voice input c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\nIt was a test of the first reusable tool.\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\nSize of armies, duration, numbers of casualt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;stuff deleted&gt;\\n\\nYou mean like: seconds, min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nIt wasn't especially prominent, as I recall....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DM&gt; Fact or rumor....?  Madalyn Murray O'Hare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\n\\n\\nIf by that you mean anything on the GD a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\nThe 68070 is a variation of the 68010 that w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PSA 145:9  The LORD is good to all: and his  t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>There has been a lot of discussion about Tyre....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>About a year ago I started work on a problem t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I need the file format for cc:Mail file format...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I've got a 386 20Hz computer which is under wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\n\\n\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\n\\tPlease do! And if you don't want to post i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>You know, it just occurred to me today that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>\\nHi,\\nIt might be nice to know, what's possib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>You have missed something.  There is a big dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>\\nSo that still leaves the door totally open f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>\\n\\n\\nI understand there have been a couple of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>\\n\\nI agree, I reckon it's television and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Speech by Pete Worden\\n                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>ZOROASTRIANISM\\nSAN JOSE, CA, USA\\nMonday Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>\\nJesus certainly demonstrated the great depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nPhil&gt; Didn't one of the early jet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>[deleted]\\n\\nThe person who was telling me abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>\\nAnd doubtless, when an atheist does an act o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>\\nLucky for them that the baby didn't have any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>\\nThere is an excellent software program calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>I'm getting ready to buy a multimedia workstat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>\\nAny lunar satellite needs fuel to do regular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>Hi there\\n\\nI am very interested in Rayshade 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>\\n\\n\\n\\nMy argument is mainly a proposal of wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>The latest news seems to be that Koresh will g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>\\nWasn't there a \"plain\" flavor too?  They loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>\\nHere is a computation I did a long time ago ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>\\n: Regardless of people's hidden motivations,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>\\nTDB&gt; 12. Disease introduced to Brazilian * o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>I am working on a program to display 3d wirefr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>\\n  Did the Russian spacecraft(s) on the ill-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>\\n\\nOh gee, a billion dollars!  That'd be just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>I am looking for software to run on my brand n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>\\n\\nThis is becoming a tiresome statement.  Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2034 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     Hi,\\n\\nI've noticed that if you only save a mo...\n",
       "1     \\n\\nSeems to be, barring evidence to the contr...\n",
       "2     \\n >In article <1993Apr19.020359.26996@sq.sq.c...\n",
       "3     I have a request for those who would like to s...\n",
       "4     AW&ST  had a brief blurb on a Manned Lunar Exp...\n",
       "5     \\nThere are definitely quite a few horrible de...\n",
       "6     Mark Prado\\n  \\n  \\nOld pioneer song from the ...\n",
       "7     \\nAcorn Replay running on a 25MHz ARM 3 proces...\n",
       "8     \\nTheir Hiten engineering-test mission spent a...\n",
       "9     I'm interested in find out what is involved in...\n",
       "10    a\\n\\nWhat about positional uncertainties in S-...\n",
       "11    I would like to program Tseng ET4000 to nonsta...\n",
       "12    In-Reply-To: <20APR199312262902@rigel.tamu.edu...\n",
       "13    \\n\\n\\n\\nI'm not sure, but it almost sounds lik...\n",
       "14    Hello,\\n     I am looking to add voice input c...\n",
       "15    \\nIt was a test of the first reusable tool.\\n\\...\n",
       "16    \\nSize of armies, duration, numbers of casualt...\n",
       "17    <stuff deleted>\\n\\nYou mean like: seconds, min...\n",
       "18    \\nIt wasn't especially prominent, as I recall....\n",
       "19    DM> Fact or rumor....?  Madalyn Murray O'Hare ...\n",
       "20    \\n\\n\\nIf by that you mean anything on the GD a...\n",
       "21    \\nThe 68070 is a variation of the 68010 that w...\n",
       "22    PSA 145:9  The LORD is good to all: and his  t...\n",
       "23    There has been a lot of discussion about Tyre....\n",
       "24    About a year ago I started work on a problem t...\n",
       "25    I need the file format for cc:Mail file format...\n",
       "26                                                     \n",
       "27    I've got a 386 20Hz computer which is under wa...\n",
       "28                                             \\n\\n\\n\\n\n",
       "29    \\n\\tPlease do! And if you don't want to post i...\n",
       "...                                                 ...\n",
       "2004  You know, it just occurred to me today that th...\n",
       "2005  \\nHi,\\nIt might be nice to know, what's possib...\n",
       "2006  You have missed something.  There is a big dif...\n",
       "2007  \\nSo that still leaves the door totally open f...\n",
       "2008  \\n\\n\\nI understand there have been a couple of...\n",
       "2009  \\n\\nI agree, I reckon it's television and the ...\n",
       "2010  Speech by Pete Worden\\n                       ...\n",
       "2011  ZOROASTRIANISM\\nSAN JOSE, CA, USA\\nMonday Apri...\n",
       "2012  \\nJesus certainly demonstrated the great depth...\n",
       "2013  \\n\\n\\n\\n\\n\\nPhil> Didn't one of the early jet ...\n",
       "2014  [deleted]\\n\\nThe person who was telling me abo...\n",
       "2015  \\nAnd doubtless, when an atheist does an act o...\n",
       "2016  \\nLucky for them that the baby didn't have any...\n",
       "2017  \\nThere is an excellent software program calle...\n",
       "2018  I'm getting ready to buy a multimedia workstat...\n",
       "2019  \\nAny lunar satellite needs fuel to do regular...\n",
       "2020  Hi there\\n\\nI am very interested in Rayshade 4...\n",
       "2021  \\n\\n\\n\\nMy argument is mainly a proposal of wh...\n",
       "2022  The latest news seems to be that Koresh will g...\n",
       "2023  \\nWasn't there a \"plain\" flavor too?  They loo...\n",
       "2024  \\nHere is a computation I did a long time ago ...\n",
       "2025  \\n: Regardless of people's hidden motivations,...\n",
       "2026  \\nTDB> 12. Disease introduced to Brazilian * o...\n",
       "2027                                                   \n",
       "2028  I am working on a program to display 3d wirefr...\n",
       "2029  \\n  Did the Russian spacecraft(s) on the ill-f...\n",
       "2030  \\n\\nOh gee, a billion dollars!  That'd be just...\n",
       "2031  I am looking for software to run on my brand n...\n",
       "2032  \\n\\nThis is becoming a tiresome statement.  Co...\n",
       "2033                                                   \n",
       "\n",
       "[2034 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(data_train.data)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of Words model\n",
    "\n",
    "Let's train a model using a simple count vectorizer\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data\n",
    "- how big is the feature dictionary\n",
    "- repeat eliminating english stop words\n",
    "- is the dictionary smaller?\n",
    "- transform the training data using the trained vectorizer\n",
    "- what are the 20 words that are most common in the whole corpus?\n",
    "- what are the 20 most common words in each of the 4 classes?\n",
    "- evaluate the performance of a Lotistic Regression on the features extracted by the CountVectorizer\n",
    "    - you will have to transform the test_set too. Be carefule to use the trained vectorizer, without re-fitting it\n",
    "- try the following 3 modification:\n",
    "    - restrict the max_features\n",
    "    - change max_df and min_df\n",
    "    - use a fixed vocabulary of size 80 combining the 20 most common words per group found earlier\n",
    "- for each of the above print a confusion matrix and investigate what gets mixed\n",
    "- print out the number of features for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat the test with no restriction on the number of features\n",
    "- does the score improve with respect to the count vectorizer?\n",
    "    - can you change any of the default parameters to improve it?\n",
    "- print out the number of features for this model\n",
    "- Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "- can you improve on your best score above?\n",
    "    - can you change any of the default parameters to improve it?\n",
    "- print out the number of features for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classifier comparison\n",
    "\n",
    "Of all the vectorizers tested above, choose one that has a reasonable performance with a manageable number of features and compare the performance of these models:\n",
    "\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "\n",
    "In order to speed up the calculation it's better to vectorize the data only once and then compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Other classifiers\n",
    "\n",
    "Adapt the code from [this example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py) to compare across all the classifiers suggested and to display the final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: NLTK\n",
    "\n",
    "NLTK is a vast library. Can you find some interesting bits to share with classmates?\n",
    "Start here: http://www.nltk.org/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
